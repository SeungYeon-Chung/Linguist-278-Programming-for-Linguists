{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Linguist 278: Programming for Linguists<br/>\n",
    "Stanford Linguistics, Fall 2020<br/>\n",
    "Christopher Potts<br/></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Assignment-6\">Assignment 6<a class=\"anchor-link\" href=\"#Assignment-6\">¶</a></h1><p>Distributed 2020-10-26<br/>\n",
    "Due 2020-11-02</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Please submit a modified version of this file with the exercise functions completed. You can add as many new cells as you want, but <strong>please make sure there are no function calls in the cells containing your implementations of the exercises</strong>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Questions\">Questions<a class=\"anchor-link\" href=\"#Questions\">¶</a></h2><ul>\n",
    "<li><a href=\"#1.-Reading-in-the-Concreteness-dataset-[1-point]\">1. Reading in the Concreteness dataset [1 point]</a></li>\n",
    "<li><a href=\"#2.-Multidimensional-sorting-[1-point]\">2. Multidimensional sorting [1 point]</a></li>\n",
    "<li><a href=\"#3.-Unigram-vs.-bigram-distribution-[1-point]\">3. Unigram vs. bigram distribution [1 point]</a></li>\n",
    "<li><a href=\"#4.-Barplot-of-the-distribution-of-part-of-speech-values-[1-point]\">4. Barplot of the distribution of part-of-speech values [1 point]</a></li>\n",
    "<li><a href=\"#5.-Subframe-of-above-average-concreteness-values-[2-points]\">5. Subframe of above-average concreteness values [2 points]</a></li>\n",
    "<li><a href=\"#6.-Recalculating-'Percent_known'--[2-points]\">6. Recalculating 'Percent_known'  [2 points]</a></li>\n",
    "<li><a href=\"#7.-Grouping-by-part-of-speech--[2-points]\">7. Grouping by part-of-speech  [2 points]</a></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"1.-Reading-in-the-Concreteness-dataset-[1-point]\">1. Reading in the Concreteness dataset [1 point]<a class=\"anchor-link\" href=\"#1.-Reading-in-the-Concreteness-dataset-[1-point]\">¶</a></h2><p><a href=\"http://crr.ugent.be/papers/Brysbaert_Warriner_Kuperman_BRM_Concreteness_ratings.pdf\">Brysbaert et al. 2014</a> released a dataset of \"concreteness ratings for 40 thousand generally known English word lemmas\". The dataset is available from this link:</p>\n",
    "<p><a href=\"http://www.humanities.mcmaster.ca/~vickup/Concreteness_ratings_Brysbaert_et_al_BRM.csv\">http://www.humanities.mcmaster.ca/~vickup/Concreteness_ratings_Brysbaert_et_al_BRM.csv</a></p>\n",
    "<p>Here is an overview of the columns and their meanings:</p>\n",
    "<ol>\n",
    "<li><code>Word</code>: The word (str; the keys in the dict/JSON)</li>\n",
    "<li><code>Bigram</code>: Whether it is a single word or a two-word expression</li>\n",
    "<li><code>Conc.M</code>: The mean concreteness rating</li>\n",
    "<li><code>Conc.SD</code>: The standard deviation of the concreteness ratings (float)</li>\n",
    "<li><code>Unknown</code>: The number of persons indicating they did not know the word</li>\n",
    "<li><code>Total</code>: The total number of persons who rated the word</li>\n",
    "<li><code>Percent_known</code>: Percentage of participants who knew the word</li>\n",
    "<li><code>SUBTLEX</code>: The SUBTLEX-US frequency count</li>\n",
    "<li><code>Dom_Pos</code>: The part-of-speech where known</li>\n",
    "</ol>\n",
    "<p><strong>Your tasks</strong>: In separate cells below this one, use pandas to</p>\n",
    "<ol>\n",
    "<li>Download this lexicon CSV file and put it in the same directory as this notebook. Please do not change the name of the file.</li>\n",
    "<li>Read the file into a <code>pd.DataFrame</code> called <code>conc_df</code> with column 0 as the index.</li>\n",
    "<li>View the first 10 lines of <code>conc_df</code>. (This is a basic method of <code>pd.DataFrame</code> – no need to write original code.)</li>\n",
    "<li>Write a command that returns the row and column counts of <code>conc_df</code> as a tuple. (This too is a basic method of <code>pd.DataFrame</code>.)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TO BE COMPLETED ##\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TO BE COMPLETED ##\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TO BE COMPLETED ##\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"2.-Multidimensional-sorting-[1-point]\">2. Multidimensional sorting [1 point]<a class=\"anchor-link\" href=\"#2.-Multidimensional-sorting-[1-point]\">¶</a></h2><p>Write a single line of code that returns a version of <code>conc_df</code> which is sorted primarily by <code>'Percent_known'</code>, largest to smallest, and by <code>'Conc.M'</code>, smallest to largest. Store the output in a variable called <code>sorted_df</code>. You can use <code>test_multidimensional_sorting</code> to test that you're sorting in the required way.</p>\n",
    "<p><strong>Hint</strong>: as you can see in the class notes, <code>sort_values</code> can take lists of column names as an argument. The same is true of the <code>ascending</code> keyword argument to <code>sort_values</code>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TO BE COMPLETED ##\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_multidimensional_sorting(sorted_df):\n",
    "    \"\"\"If you capture the output of your sorting in a dataframe\n",
    "    and feed it into this function, it will run a basic test\n",
    "    on that dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "    expected = ['although', 'spirituality', 'spiritually',\n",
    "                'whatsoever', 'enlightening', 'perhaps',\n",
    "                'if', 'belief', 'idealize', 'though']\n",
    "    result = list(sorted_df.index[: 10])\n",
    "    assert expected == result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If your test passes, this will produce no output. If it fails,\n",
    "# you'll see an assertion error:\n",
    "\n",
    "test_multidimensional_sorting(sorted_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"3.-Unigram-vs.-bigram-distribution-[1-point]\">3. Unigram vs. bigram distribution [1 point]<a class=\"anchor-link\" href=\"#3.-Unigram-vs.-bigram-distribution-[1-point]\">¶</a></h2><p>Complete <code>bigram_distribution</code> according to its docstring. You can use <code>test_bigram_distribution</code> to check your code.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bigram_distribution(conc_df):\n",
    "    \"\"\"Return the distribution of values in the 'Bigram' column\n",
    "    of the concreteness lexicon.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conc_df : pd.DataFrame\n",
    "        The concreteness lexicon.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "    \"\"\"\n",
    "    ## TO BE COMPLETED ##\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_bigram_distribution(words_df):\n",
    "    expected = pd.Series({0: 37058, 1: 2896})\n",
    "    assert bigram_distribution(words_df).all() == expected.all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If your test passes, this will produce no output. If it fails,\n",
    "# you'll see an assertion error:\n",
    "\n",
    "test_bigram_distribution(conc_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"4.-Barplot-of-the-distribution-of-part-of-speech-values-[1-point]\">4. Barplot of the distribution of part-of-speech values [1 point]<a class=\"anchor-link\" href=\"#4.-Barplot-of-the-distribution-of-part-of-speech-values-[1-point]\">¶</a></h2><p>Write code to produce a horizontal barplot giving the distribution of the<code>'Dom_Pos'</code> values in <code>conc_df</code>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TO BE COMPLETED ##\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"5.-Subframe-of-above-average-concreteness-values-[2-points]\">5. Subframe of above-average concreteness values [2 points]<a class=\"anchor-link\" href=\"#5.-Subframe-of-above-average-concreteness-values-[2-points]\">¶</a></h2><p>Write code to pull out the subframe of <code>conc_df</code> in which the <code>'Conc.M'</code> values are greater than the mean for those values in the entire lexicon, and store this in a variable called <code>mu_df</code>. <strong>The resulting frame has 18,273 rows</strong>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TO BE COMPLETED ##\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert mu_df.shape[0] == 18273\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"6.-Recalculating-'Percent_known'--[2-points]\">6. Recalculating 'Percent_known'  [2 points]<a class=\"anchor-link\" href=\"#6.-Recalculating-'Percent_known'--[2-points]\">¶</a></h2><p>This question asks you to create a useful <code>pd.Series</code> based on the conceretness lexicon. The full desired specification is given in the docstring.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recalculate_percent_known(conc_df):\n",
    "    \"\"\"In the Concreteness lexicon, the 'Unknown' values divided by\n",
    "    the 'Total' values give us the percent unknown, and 1.0 minus those\n",
    "    values give us the 'Percent_known' values but at a greater level of\n",
    "    precision. The current function recomputes these values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conc_df : pd.DataFrame\n",
    "        The concreteness lexicon.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Containing the calculated percent known values\n",
    "        for each word in the lexicon\n",
    "\n",
    "    \"\"\"\n",
    "    ## TO BE COMPLETED ##\n",
    "    pass\n",
    "\n",
    "def test_recalculate_percent_known(conc_df):\n",
    "    pk = recalculate_percent_known(conc_df)\n",
    "    examples = [\n",
    "        ('roadsweeper', 0.963),\n",
    "        ('hairdress', 1.0),\n",
    "        ('bobsleigh', 0.8462)]\n",
    "    for ex, expected in examples:\n",
    "        result = pk[ex].round(4)\n",
    "        assert result == expected, \\\n",
    "            \"For {}, expected {}; got {}\".format(ex, expected, result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# If your test passes, this will produce no output. If it fails,\n",
    "# you'll see an assertion error:\n",
    "\n",
    "test_recalculate_percent_known(conc_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"7.-Grouping-by-part-of-speech--[2-points]\">7. Grouping by part-of-speech  [2 points]<a class=\"anchor-link\" href=\"#7.-Grouping-by-part-of-speech--[2-points]\">¶</a></h2><p>This question asks you to use <code>groupby</code> to get the mean 'Percent_known' for each part-of-speech ('Dom_Pos' column). The return value is a <code>pd.Series</code>, and it should be sorted from largest to smallest mean 'Percent_known' value.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def percent_known_by_pos(conc_df):\n",
    "    \"\"\"Gets the mean 'Percent_known' for each part-of-speech\n",
    "    ('Dom_Pos' column), and return a `pd.Series` sorted from\n",
    "    largest mean 'Percent_known' to smallest.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    conc_df : pd.DataFrame\n",
    "        The concreteness lexicon.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "    \"\"\"\n",
    "\n",
    "    def mean_percent_known(grp):\n",
    "        \"\"\"This is the function to apply to each group.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        grp : pd.DataFrame\n",
    "            As created by `groupby`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "            Giving the mean of the 'Percent_known' column\n",
    "            in `grp`.\n",
    "\n",
    "        \"\"\"\n",
    "        ## TO BE COMPLETED ##\n",
    "         pass\n",
    "\n",
    "    ## TO BE COMPLETED ##\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_percent_known_by_pos(conc_df):\n",
    "    result = percent_known_by_pos(conc_df)\n",
    "    examples = (\n",
    "        (0, 'To', 1.000),\n",
    "        (3, 'Determiner', 0.995),\n",
    "        (-1, 'Unclassified', 0.917))\n",
    "    err_count = 0\n",
    "    for i, pos, val in examples:\n",
    "        if result.index[i] != pos:\n",
    "            print(\"Expected {} at row {}; got {}\".format(pos, i, result.index[i]))\n",
    "            err_count += 1\n",
    "        if pos not in result:\n",
    "            print(\"Key {} is not present\".format(pos))\n",
    "            err_count += 1\n",
    "        elif result.loc[pos].round(3) != val:\n",
    "            print(\"Expected value {} for {}; got {}\".format(val, pos, result.loc[pos]))\n",
    "            err_count += 1\n",
    "    print(\"test_percent_known_by_pos completed with {} errors\".format(err_count))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_percent_known_by_pos(conc_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
